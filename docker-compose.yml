# ==================== Docker Compose - Production ====================
# Optimized for production with slim images
# Kubernetes-ready with proper health checks and restart policies
#
# Usage:
#   docker compose up -d              # Start all services
#   docker compose up -d --build      # Rebuild and start
#   docker compose logs -f            # View logs
#   docker compose down               # Stop all services
#
# Health check endpoints:
#   Backend: GET /health, /ready, /live
#   Worker: celery inspect ping
#   Beat: pidfile check

version: "3.9"

# ==================== Common Configuration ====================
x-backend-common: &backend-common
  build:
    context: ./backend
    dockerfile: Dockerfile
  environment: &backend-env
    - DATABASE_URL=postgresql+psycopg2://postgres:postgres@db:5432/eli_maor
    - REDIS_URL=redis://redis:6379/0
    - SECRET_KEY=${SECRET_KEY}
    - GOOGLE_CLIENT_ID=${GOOGLE_CLIENT_ID}
    - GOOGLE_CLIENT_SECRET=${GOOGLE_CLIENT_SECRET}
    - VAPID_PRIVATE_KEY=${VAPID_PRIVATE_KEY}
    - VAPID_PUBLIC_KEY=${VAPID_PUBLIC_KEY}
    - ENVIRONMENT=production
  depends_on:
    db:
      condition: service_healthy
    redis:
      condition: service_healthy
  restart: unless-stopped
  networks:
    - app-network

# Healthcheck defaults for reuse
x-healthcheck-defaults: &healthcheck-defaults
  interval: 30s
  timeout: 10s
  retries: 3
  start_period: 30s

services:
  # ==================== Database ====================
  db:
    image: postgres:16-alpine
    container_name: eli_maor_db
    hostname: db
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_DB: eli_maor
      # Performance tuning
      POSTGRES_INITDB_ARGS: "--encoding=UTF8"
    volumes:
      - pg_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres -d eli_maor"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    restart: unless-stopped
    networks:
      - app-network
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M
    labels:
      - "app.service=database"
      - "app.tier=data"

  # ==================== Redis ====================
  redis:
    image: redis:7-alpine
    container_name: eli_maor_redis
    hostname: redis
    command: >
      redis-server
      --appendonly yes
      --maxmemory 256mb
      --maxmemory-policy allkeys-lru
      --tcp-keepalive 60
      --timeout 0
    volumes:
      - redis_data:/data
    ports:
      - "6379:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 5s
    restart: unless-stopped
    networks:
      - app-network
    deploy:
      resources:
        limits:
          memory: 256M
        reservations:
          memory: 128M
    labels:
      - "app.service=cache"
      - "app.tier=data"

  # ==================== Backend API ====================
  backend:
    <<: *backend-common
    container_name: eli_maor_backend
    hostname: backend
    command: >
      sh -c "alembic upgrade head &&
             uvicorn app.main:app --host 0.0.0.0 --port 8000 --workers 2 --access-log"
    ports:
      - "8000:8000"
    healthcheck:
      # Use /ready for Kubernetes readiness probe (checks DB + Redis)
      # Use /live for liveness probe (simple check)
      test: ["CMD", "curl", "-f", "http://localhost:8000/health/ready"]
      <<: *healthcheck-defaults
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M
      # Kubernetes-style restart policy
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
        window: 120s
    labels:
      - "app.service=api"
      - "app.tier=backend"
      - "traefik.enable=true"
      - "traefik.http.routers.backend.rule=PathPrefix(`/api`)"

  # ==================== Celery Worker ====================
  worker:
    <<: *backend-common
    container_name: eli_maor_worker
    hostname: worker
    command: >
      celery -A app.workers.celery_app.celery worker
      --loglevel=info
      --concurrency=2
      --max-tasks-per-child=1000
      --prefetch-multiplier=4
    healthcheck:
      # Check if celery worker is responsive
      test: ["CMD-SHELL", "celery -A app.workers.celery_app.celery inspect ping -d celery@$$HOSTNAME || exit 1"]
      interval: 60s
      timeout: 30s
      retries: 3
      start_period: 60s
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M
      restart_policy:
        condition: on-failure
        delay: 10s
        max_attempts: 5
        window: 120s
    labels:
      - "app.service=worker"
      - "app.tier=backend"

  # ==================== Celery Beat (Scheduler) ====================
  beat:
    <<: *backend-common
    container_name: eli_maor_beat
    hostname: beat
    command: >
      celery -A app.workers.celery_app.celery beat
      --loglevel=info
      --pidfile=/tmp/celerybeat.pid
      --schedule=/tmp/celerybeat-schedule
    depends_on:
      worker:
        condition: service_healthy
    healthcheck:
      # Check if beat pidfile exists and process is running
      test: ["CMD-SHELL", "test -f /tmp/celerybeat.pid && kill -0 $$(cat /tmp/celerybeat.pid) 2>/dev/null || exit 1"]
      interval: 60s
      timeout: 10s
      retries: 3
      start_period: 30s
    deploy:
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 64M
      restart_policy:
        condition: on-failure
        delay: 10s
        max_attempts: 5
        window: 120s
    labels:
      - "app.service=scheduler"
      - "app.tier=backend"

  # ==================== Frontend ====================
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
      args:
        - VITE_API_URL=${VITE_API_URL:-http://localhost:8000}
        - VITE_WS_URL=${VITE_WS_URL:-ws://localhost:8000}
        - VITE_VAPID_PUBLIC_KEY=${VAPID_PUBLIC_KEY}
        - NODE_ENV=production
    container_name: eli_maor_frontend
    hostname: frontend
    environment:
      - BACKEND_URL=http://backend:8000
    ports:
      - "3000:80"
    depends_on:
      backend:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:80/"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 10s
    restart: unless-stopped
    networks:
      - app-network
    deploy:
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 64M
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
        window: 60s
    labels:
      - "app.service=frontend"
      - "app.tier=frontend"
      - "traefik.enable=true"
      - "traefik.http.routers.frontend.rule=PathPrefix(`/`)"

  # ==================== Flower (Celery Monitoring) - Optional ====================
  # Uncomment for production monitoring
  # flower:
  #   <<: *backend-common
  #   container_name: eli_maor_flower
  #   hostname: flower
  #   command: >
  #     celery -A app.workers.celery_app.celery flower
  #     --port=5555
  #     --basic_auth=${FLOWER_USER:-admin}:${FLOWER_PASSWORD:-admin}
  #   ports:
  #     - "5555:5555"
  #   healthcheck:
  #     test: ["CMD", "curl", "-f", "http://localhost:5555/healthcheck"]
  #     interval: 30s
  #     timeout: 10s
  #     retries: 3
  #     start_period: 30s
  #   depends_on:
  #     worker:
  #       condition: service_healthy
  #   deploy:
  #     resources:
  #       limits:
  #         memory: 256M
  #   labels:
  #     - "app.service=monitoring"
  #     - "app.tier=observability"

  # ==================== ML Service (Optional) ====================
  # Uncomment if you need to run custom ML models
  # ml-service:
  #   build: ./ml-service
  #   container_name: eli_maor_ml_service
  #   hostname: ml-service
  #   ports:
  #     - "8001:8001"
  #   environment:
  #     - MODEL_CACHE_DIR=/app/models
  #   volumes:
  #     - ml_cache:/app/.cache
  #   healthcheck:
  #     test: ["CMD", "curl", "-f", "http://localhost:8001/health"]
  #     interval: 30s
  #     timeout: 10s
  #     retries: 3
  #     start_period: 60s
  #   restart: unless-stopped
  #   networks:
  #     - app-network
  #   deploy:
  #     resources:
  #       limits:
  #         memory: 4G
  #       reservations:
  #         memory: 2G
  #   labels:
  #     - "app.service=ml"
  #     - "app.tier=backend"

# ==================== Networks ====================
networks:
  app-network:
    driver: bridge
    ipam:
      driver: default
      config:
        - subnet: 172.28.0.0/16

# ==================== Volumes ====================
volumes:
  pg_data:
    driver: local
  redis_data:
    driver: local
  # ml_cache:
  #   driver: local
